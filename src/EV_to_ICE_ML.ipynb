{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stas420/machine_learning_ev_ice/blob/main/src/EV_to_ICE_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup and dependencies\n",
        "Run the below cell, which shall clone the repo contents and prepare the machine for work. This may take a few minutes.\n",
        "\n",
        "***Important:*** This is the first cell you shall run in this project, otherwise it won't be working.\n",
        "\n",
        "After 'pip' is done, it may ask you to restart this session - please do accordingly."
      ],
      "metadata": {
        "id": "PRPDslf-MuH0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oB99vcFrGWR",
        "outputId": "df791624-cce6-4a3f-a514-7341642cbe78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'machine_learning_ev_ice'...\n",
            "remote: Enumerating objects: 69, done.\u001b[K\n",
            "remote: Counting objects: 100% (69/69), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 69 (delta 32), reused 39 (delta 11), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (69/69), 5.70 MiB | 19.40 MiB/s, done.\n",
            "Resolving deltas: 100% (32/32), done.\n",
            "/content/machine_learning_ev_ice\n",
            "Already up to date.\n",
            "/content/machine_learning_ev_ice/src\n",
            "Requirement already satisfied: setuptools==78.1.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (78.1.0)\n",
            "Requirement already satisfied: labelImg==1.8.6 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (1.8.6)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy==2.2.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (2.2.4)\n",
            "Requirement already satisfied: ultralytics==8.3.140 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (8.3.140)\n",
            "Requirement already satisfied: opencv-python-headless==4.11.0.86 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (4.11.0.86)\n",
            "Requirement already satisfied: tqdm==4.67.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (4.67.1)\n",
            "Requirement already satisfied: pyqt5 in /usr/local/lib/python3.11/dist-packages (from labelImg==1.8.6->-r requirements.txt (line 3)) (5.15.11)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from labelImg==1.8.6->-r requirements.txt (line 3)) (5.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 6)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 6)) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 6)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 6)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 6)) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 6)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 6)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 6)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 6)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 6)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 6)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 6)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 6)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 6)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 6)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 6)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 6)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 6)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 6)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 6)) (1.13.1)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.140->-r requirements.txt (line 8)) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.140->-r requirements.txt (line 8)) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.140->-r requirements.txt (line 8)) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.140->-r requirements.txt (line 8)) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.140->-r requirements.txt (line 8)) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.140->-r requirements.txt (line 8)) (1.15.3)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.140->-r requirements.txt (line 8)) (0.21.0+cu124)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.140->-r requirements.txt (line 8)) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.140->-r requirements.txt (line 8)) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.140->-r requirements.txt (line 8)) (2.2.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.140->-r requirements.txt (line 8)) (2.0.14)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->-r requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.140->-r requirements.txt (line 8)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.140->-r requirements.txt (line 8)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.140->-r requirements.txt (line 8)) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.140->-r requirements.txt (line 8)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.140->-r requirements.txt (line 8)) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.140->-r requirements.txt (line 8)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.140->-r requirements.txt (line 8)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics==8.3.140->-r requirements.txt (line 8)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics==8.3.140->-r requirements.txt (line 8)) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.3.140->-r requirements.txt (line 8)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.3.140->-r requirements.txt (line 8)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.3.140->-r requirements.txt (line 8)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.3.140->-r requirements.txt (line 8)) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->-r requirements.txt (line 6)) (3.0.2)\n",
            "Requirement already satisfied: PyQt5-sip<13,>=12.15 in /usr/local/lib/python3.11/dist-packages (from pyqt5->labelImg==1.8.6->-r requirements.txt (line 3)) (12.17.0)\n",
            "Requirement already satisfied: PyQt5-Qt5<5.16.0,>=5.15.2 in /usr/local/lib/python3.11/dist-packages (from pyqt5->labelImg==1.8.6->-r requirements.txt (line 3)) (5.15.16)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.3.140->-r requirements.txt (line 8)) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# remove possible leftovers and clear-clone the whole repo\n",
        "%cd /content\n",
        "%rm -rf ./machine_learning_ev_ice\n",
        "!git clone https://github.com/stas420/machine_learning_ev_ice.git\n",
        "\n",
        "# a git pull pro forma\n",
        "%cd ./machine_learning_ev_ice\n",
        "!git pull\n",
        "\n",
        "# go to our main directory\n",
        "%cd ./src\n",
        "\n",
        "# check (and download, if needed) dependencies for the project\n",
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# małnt dejta\n",
        "\n",
        "tu sb poberamy dane z podmontowanego dysku gugl"
      ],
      "metadata": {
        "id": "ipp6kZ_9NTTK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IeZ7a9crGWT",
        "outputId": "a9365e85-4094-4961-c814-2377d8620d9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "if not 'drive' in os.listdir():\n",
        "  drive.mount('/content/drive')\n",
        "else:\n",
        "  print(\"drajw dajrektory alredi prezent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a tu sb dodamy zmienne globalne UwU"
      ],
      "metadata": {
        "id": "WQpmgashBupp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VIDEOS_PATH = '/content/drive/MyDrive/videos'\n",
        "IMAGES_PATH = '/content/imgs'"
      ],
      "metadata": {
        "id": "VTmr5b5lBuOP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# extrakt frejms"
      ],
      "metadata": {
        "id": "F5sCM44OjlQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clearing leftovers pro forma\n",
        "%rm -rf /content/imgs\n",
        "%mkdir /content/imgs\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# function which takes a .mp4 file and extracts its frames,\n",
        "# then saves them as images in the provided directory\n",
        "def extract_frames(video_path, output_dir, fps=1) -> None:\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    count = 0\n",
        "    saved = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        else:\n",
        "            frame_path = os.path.join(output_dir, f\"frame_{saved:03d}.jpg\")\n",
        "            cv2.imwrite(frame_path, frame)\n",
        "            saved += 1\n",
        "        count += 1\n",
        "    cap.release()\n",
        "\n",
        "# image extraction\n",
        "for x in os.listdir(VIDEOS_PATH):\n",
        "  extract_frames(VIDEOS_PATH + '/' + x, \"/content/imgs/\" + x, fps=1)\n",
        "\n",
        "!ls -la ./content/imgs"
      ],
      "metadata": {
        "id": "eBpUp2Lxjm1R",
        "outputId": "8155fa73-adb7-47fc-979d-215dd0a792e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-69b9ebd8e8bd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# image extraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVIDEOS_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m   \u001b[0mextract_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVIDEOS_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/imgs/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ls -la ./content/imgs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-69b9ebd8e8bd>\u001b[0m in \u001b[0;36mextract_frames\u001b[0;34m(video_path, output_dir, fps)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# is grin plejt"
      ],
      "metadata": {
        "id": "BGA7EFkJgUZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/machine_learning_ev_ice/src\n",
        "\n",
        "# for development only, suck my ass!\n",
        "%rm -rf /content/results\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "def is_green_plate(plate_img):\n",
        "    hsv = cv2.cvtColor(plate_img, cv2.COLOR_BGR2HSV)\n",
        "    h, s, _ = hsv.mean(axis=0).mean(axis=0)\n",
        "    return 35 < h < 85 and s > 40\n",
        "\n",
        "model = YOLO('./yolov8n.pt')\n",
        "input_dir = \"/content/imgs/2024-01-29.mp4\"\n",
        "output_dir = \"/content/results\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for fname in os.listdir(input_dir):\n",
        "    if not fname.endswith(\".jpg\"):\n",
        "        continue\n",
        "    path = os.path.join(input_dir, fname)\n",
        "    img = cv2.imread(path)\n",
        "    results = model(img)\n",
        "\n",
        "    for box in results[0].boxes:\n",
        "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "        crop = img[y1:y2, x1:x2]\n",
        "        label = \"green\" if is_green_plate(crop) else \"normal\"\n",
        "        color = (0,255,0) if label == \"green\" else (255,0,0)\n",
        "\n",
        "        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
        "        cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
        "\n",
        "    cv2.imwrite(os.path.join(output_dir, fname), img)\n"
      ],
      "metadata": {
        "id": "pRG7YckugWgM",
        "outputId": "585a2d12-51dc-40c5-a365-25d18a89c771",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/machine_learning_ev_ice/src\n",
            "\n",
            "0: 384x640 (no detections), 165.8ms\n",
            "Speed: 4.6ms preprocess, 165.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 150.5ms\n",
            "Speed: 5.1ms preprocess, 150.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 150.6ms\n",
            "Speed: 5.6ms preprocess, 150.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 148.5ms\n",
            "Speed: 5.1ms preprocess, 148.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 150.3ms\n",
            "Speed: 5.3ms preprocess, 150.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20 cars, 1 truck, 1 traffic light, 154.5ms\n",
            "Speed: 5.0ms preprocess, 154.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 166.4ms\n",
            "Speed: 4.6ms preprocess, 166.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21 cars, 148.6ms\n",
            "Speed: 5.0ms preprocess, 148.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 150.7ms\n",
            "Speed: 5.8ms preprocess, 150.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 159.9ms\n",
            "Speed: 5.5ms preprocess, 159.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 154.8ms\n",
            "Speed: 5.0ms preprocess, 154.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 156.9ms\n",
            "Speed: 3.9ms preprocess, 156.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 cars, 170.7ms\n",
            "Speed: 5.3ms preprocess, 170.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 154.7ms\n",
            "Speed: 5.5ms preprocess, 154.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 150.4ms\n",
            "Speed: 3.9ms preprocess, 150.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 150.0ms\n",
            "Speed: 5.4ms preprocess, 150.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 cars, 154.9ms\n",
            "Speed: 3.8ms preprocess, 154.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 159.5ms\n",
            "Speed: 5.3ms preprocess, 159.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 176.0ms\n",
            "Speed: 5.5ms preprocess, 176.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 572.3ms\n",
            "Speed: 9.7ms preprocess, 572.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 153.9ms\n",
            "Speed: 6.5ms preprocess, 153.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 164.7ms\n",
            "Speed: 4.3ms preprocess, 164.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 cars, 420.7ms\n",
            "Speed: 5.8ms preprocess, 420.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 302.6ms\n",
            "Speed: 10.1ms preprocess, 302.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 175.7ms\n",
            "Speed: 6.5ms preprocess, 175.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 cars, 155.1ms\n",
            "Speed: 5.3ms preprocess, 155.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 525.1ms\n",
            "Speed: 8.7ms preprocess, 525.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 150.5ms\n",
            "Speed: 5.4ms preprocess, 150.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 cars, 1 truck, 171.1ms\n",
            "Speed: 5.2ms preprocess, 171.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 147.9ms\n",
            "Speed: 5.5ms preprocess, 147.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 149.4ms\n",
            "Speed: 5.7ms preprocess, 149.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 cars, 164.3ms\n",
            "Speed: 4.3ms preprocess, 164.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 156.3ms\n",
            "Speed: 5.6ms preprocess, 156.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5 cars, 156.0ms\n",
            "Speed: 5.4ms preprocess, 156.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 157.1ms\n",
            "Speed: 6.8ms preprocess, 157.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 cars, 152.6ms\n",
            "Speed: 5.3ms preprocess, 152.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 154.4ms\n",
            "Speed: 5.3ms preprocess, 154.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 truck, 156.8ms\n",
            "Speed: 5.4ms preprocess, 156.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 cars, 159.0ms\n",
            "Speed: 5.1ms preprocess, 159.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 cars, 170.7ms\n",
            "Speed: 4.8ms preprocess, 170.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 151.9ms\n",
            "Speed: 5.2ms preprocess, 151.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 150.8ms\n",
            "Speed: 5.4ms preprocess, 150.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 152.9ms\n",
            "Speed: 7.8ms preprocess, 152.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 cars, 152.1ms\n",
            "Speed: 5.6ms preprocess, 152.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 153.5ms\n",
            "Speed: 4.8ms preprocess, 153.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 175.5ms\n",
            "Speed: 5.4ms preprocess, 175.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 154.2ms\n",
            "Speed: 5.3ms preprocess, 154.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 195.7ms\n",
            "Speed: 5.2ms preprocess, 195.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 250.1ms\n",
            "Speed: 5.8ms preprocess, 250.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 253.6ms\n",
            "Speed: 4.3ms preprocess, 253.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 232.4ms\n",
            "Speed: 5.6ms preprocess, 232.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 cars, 233.1ms\n",
            "Speed: 5.9ms preprocess, 233.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 226.7ms\n",
            "Speed: 6.8ms preprocess, 226.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 cars, 240.5ms\n",
            "Speed: 5.9ms preprocess, 240.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 262.9ms\n",
            "Speed: 7.9ms preprocess, 262.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 cars, 234.4ms\n",
            "Speed: 6.1ms preprocess, 234.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18 cars, 255.8ms\n",
            "Speed: 6.8ms preprocess, 255.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 cars, 235.8ms\n",
            "Speed: 5.7ms preprocess, 235.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 228.6ms\n",
            "Speed: 6.7ms preprocess, 228.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 237.9ms\n",
            "Speed: 7.6ms preprocess, 237.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 251.8ms\n",
            "Speed: 6.1ms preprocess, 251.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 250.8ms\n",
            "Speed: 7.0ms preprocess, 250.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 1 bench, 238.5ms\n",
            "Speed: 6.4ms preprocess, 238.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 233.2ms\n",
            "Speed: 6.2ms preprocess, 233.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 156.7ms\n",
            "Speed: 4.5ms preprocess, 156.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 1 truck, 152.4ms\n",
            "Speed: 5.4ms preprocess, 152.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 174.1ms\n",
            "Speed: 6.7ms preprocess, 174.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 153.1ms\n",
            "Speed: 5.6ms preprocess, 153.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 cars, 1 traffic light, 152.0ms\n",
            "Speed: 6.3ms preprocess, 152.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 158.8ms\n",
            "Speed: 5.1ms preprocess, 158.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 cars, 151.4ms\n",
            "Speed: 5.4ms preprocess, 151.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19 cars, 1 bus, 2 trucks, 150.8ms\n",
            "Speed: 5.2ms preprocess, 150.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 suitcase, 167.1ms\n",
            "Speed: 5.2ms preprocess, 167.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 cars, 155.2ms\n",
            "Speed: 5.1ms preprocess, 155.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 156.3ms\n",
            "Speed: 6.5ms preprocess, 156.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 156.6ms\n",
            "Speed: 5.4ms preprocess, 156.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 cars, 149.9ms\n",
            "Speed: 5.5ms preprocess, 149.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 cars, 1 traffic light, 152.3ms\n",
            "Speed: 5.2ms preprocess, 152.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 177.1ms\n",
            "Speed: 5.4ms preprocess, 177.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 156.4ms\n",
            "Speed: 5.4ms preprocess, 156.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 159.1ms\n",
            "Speed: 5.4ms preprocess, 159.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 151.5ms\n",
            "Speed: 5.9ms preprocess, 151.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 cars, 1 truck, 151.7ms\n",
            "Speed: 5.2ms preprocess, 151.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 156.2ms\n",
            "Speed: 5.9ms preprocess, 156.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 cars, 159.6ms\n",
            "Speed: 5.7ms preprocess, 159.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 152.9ms\n",
            "Speed: 5.2ms preprocess, 152.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 161.3ms\n",
            "Speed: 4.3ms preprocess, 161.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 148.9ms\n",
            "Speed: 5.2ms preprocess, 148.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 cars, 153.8ms\n",
            "Speed: 5.2ms preprocess, 153.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# prawdziwe mlowanie\n"
      ],
      "metadata": {
        "id": "pWtCZg8DNPf5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OXLvE_UK2xN",
        "outputId": "c68f585d-e903-4523-fad5-b68db061cf7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9320, 0.5988, 0.1856],\n",
            "        [0.5191, 0.3469, 0.9685],\n",
            "        [0.1125, 0.9076, 0.0556],\n",
            "        [0.0212, 0.8824, 0.7880],\n",
            "        [0.8299, 0.5203, 0.5885]])\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# 2. Wczytanie modelu YOLO (np. wytrenowany na tablicach)\n",
        "model = YOLO(\"../models/license_plate.pt\")\n",
        "\n",
        "# 3. Wczytanie przykładowego obrazu\n",
        "image_path = \"../data/frames/frame_01.jpg\"\n",
        "image = cv2.imread(image_path)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# 4. Detekcja tablic rejestracyjnych\n",
        "results = model(image)\n",
        "\n",
        "# 5. Analiza i klasyfikacja kolorów tablic\n",
        "for box in results[0].boxes:\n",
        "    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "    cropped = image[y1:y2, x1:x2]\n",
        "\n",
        "    # Analiza koloru – przejście na HSV\n",
        "    hsv = cv2.cvtColor(cropped, cv2.COLOR_BGR2HSV)\n",
        "    avg_color = hsv.mean(axis=0).mean(axis=0)\n",
        "\n",
        "    # Detekcja zielonej barwy\n",
        "    h, s, v = avg_color\n",
        "    is_green = 35 < h < 85 and s > 40\n",
        "\n",
        "    color_label = \"ZIELONA (elektryczny)\" if is_green else \"Zwykła\"\n",
        "\n",
        "    # Rysowanie wyników\n",
        "    cv2.rectangle(image, (x1, y1), (x2, y2), (0,255,0) if is_green else (255,0,0), 2)\n",
        "    cv2.putText(image, color_label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9,\n",
        "                (0,255,0) if is_green else (255,0,0), 2)\n",
        "\n",
        "# 6. Wyświetlenie wyników\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6ZA89xgozHj"
      },
      "source": [
        "Dżem dobry\n",
        ":)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}